{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images (Don't use this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = 'ran-d/' # the dataset file or root folder path.\n",
    "MODE = 'folder'\n",
    "# Image Parameters\n",
    "N_CLASSES = 1 # CHANGE HERE, total number of classes\n",
    "IMG_HEIGHT = 28 # CHANGE HERE, the image height to be resized to\n",
    "IMG_WIDTH = 28 # CHANGE HERE, the image width to be resized to\n",
    "CHANNELS = 1 # The 3 color channels, change to 1 if grayscale\n",
    "\n",
    "## Load images to tensor (Don't use)\n",
    "\n",
    "def read_images(dataset_path, mode, batch_size):\n",
    "    tf.reset_default_graph()\n",
    "    imagepaths, labels = list(), list()\n",
    "    if mode == 'file':\n",
    "        # Read dataset file\n",
    "        data = open(dataset_path, 'r').read().splitlines()\n",
    "        for d in data:\n",
    "            imagepaths.append(d.split(' ')[0])\n",
    "            labels.append(int(d.split(' ')[1]))\n",
    "    elif mode == 'folder':\n",
    "        # An ID will be affected to each sub-folders by alphabetical order\n",
    "        label = 0\n",
    "        # List the directory\n",
    "        \n",
    "        classes = sorted(os.walk(dataset_path).__next__()[1])\n",
    "        # List each sub-directory (the classes)\n",
    "        for c in classes:\n",
    "            c_dir = os.path.join(dataset_path, c)\n",
    "            try:  # Python 2\n",
    "                walk = os.walk(c_dir).next()\n",
    "            except Exception:  # Python 3\n",
    "                walk = os.walk(c_dir).__next__()\n",
    "            # Add each image to the training set\n",
    "            for sample in walk[2]:\n",
    "                # Only keeps jpeg images\n",
    "                if sample.endswith('.jpg') or sample.endswith('.jpeg'):\n",
    "                    imagepaths.append(os.path.join(c_dir, sample))\n",
    "                    labels.append(label)\n",
    "            label += 1\n",
    "    else:\n",
    "        raise Exception(\"Unknown mode.\")\n",
    "\n",
    "    # Convert to Tensor\n",
    "    imagepaths = tf.convert_to_tensor(imagepaths, dtype=tf.string)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "    # Build a TF Queue, shuffle data\n",
    "    image, label = tf.train.slice_input_producer([imagepaths, labels],\n",
    "                                                 shuffle=True)\n",
    "    \n",
    "    # Read images from disk\n",
    "    image = tf.read_file(image)\n",
    "    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n",
    "    # Resize images to a common size\n",
    "    image = tf.image.resize_images(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "\n",
    "    # Normalize\n",
    "    image = image * 1.0/127.5 - 1.0\n",
    "    \n",
    "    # Create batches\n",
    "    X, Y = tf.train.batch([image, label], batch_size=batch_size,\n",
    "                          capacity=batch_size * 8,\n",
    "                          num_threads=4)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "real_images,one_hot_labels = read_images(DATASET_PATH,MODE,batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images (Use this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "size = 28,28\n",
    "X_data = []\n",
    "files = glob.glob (\"ran-d/*.jpg\") # Add the path to dataset here\n",
    "for myFile in files:\n",
    "    print(myFile)\n",
    "    image = cv2.imread(myFile, 0)\n",
    "    resized_image = cv2.resize(image, (28, 28)) \n",
    "    X_data.append(resized_image)\n",
    "\n",
    "print('X_data shape:', np.array(X_data).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_final = np.array(X_data).reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3651, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x_image, reuse=False):\n",
    "    if (reuse):\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "    #Conv block 1\n",
    "    d_w1 = tf.get_variable('d_w1', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))\n",
    "    d1 = tf.nn.conv2d(input=x_image, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    d1 = d1 + d_b1\n",
    "    d1 = tf.nn.relu(d1)\n",
    "    d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    #Conv block 2\n",
    "    d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "    d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    d2 = d2 + d_b2\n",
    "    d2 = tf.nn.relu(d2)\n",
    "    d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    #Dense block 1\n",
    "    d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "    d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "    d3 = tf.matmul(d3, d_w3)\n",
    "    d3 = d3 + d_b3\n",
    "    d3 = tf.nn.relu(d3)\n",
    "\n",
    "    #Dense block 2\n",
    "    d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "    d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "\n",
    "    return d4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(batch_size, z_dim):\n",
    "    z = tf.truncated_normal([batch_size, z_dim], mean=0, stddev=1, name='z')\n",
    "    #first deconv block\n",
    "    g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g1 = tf.matmul(z, g_w1) + g_b1\n",
    "    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "    g1 = tf.nn.relu(g1)\n",
    "\n",
    "    # Generate 50 features\n",
    "    g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g2 = g2 + g_b2\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    g2 = tf.image.resize_images(g2, [56, 56])\n",
    "\n",
    "    # Generate 25 features\n",
    "    g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g3 = g3 + g_b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56, 56])\n",
    "\n",
    "    # Final convolution with one output channel\n",
    "    g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g4 = g4 + g_b4\n",
    "    g4 = tf.sigmoid(g4)\n",
    "    # Dimensions of g4: batch_size x 28 x 28 x 1\n",
    "\n",
    "    return g4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config session and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config, ...)\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "batch_size = 50\n",
    "z_dimensions = 100\n",
    "\n",
    "x_placeholder = tf.placeholder(\"float\", shape = [None,28,28,1], name='x_placeholder')\n",
    "\n",
    "Gz = generator(batch_size, z_dimensions)\n",
    "\n",
    "Dx = discriminator(x_placeholder)\n",
    "\n",
    "Dg = discriminator(Gz, reuse=True)\n",
    "\n",
    "\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.ones_like(Dg)))\n",
    "\n",
    "\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dx, labels=tf.fill([batch_size, 1], 0.9)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.zeros_like(Dg)))\n",
    "d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "\n",
    "with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE) as scope:\n",
    "    \n",
    "    d_trainer_fake = tf.train.AdamOptimizer(0.0001).minimize(d_loss_fake, var_list=d_vars)\n",
    "    d_trainer_real = tf.train.AdamOptimizer(0.0001).minimize(d_loss_real, var_list=d_vars)\n",
    "    g_trainer = tf.train.AdamOptimizer(0.0001).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log the model on tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard/gan/\n"
     ]
    }
   ],
   "source": [
    "tf.summary.scalar('Generator_loss', g_loss)\n",
    "tf.summary.scalar('Discriminator_loss_real', d_loss_real)\n",
    "tf.summary.scalar('Discriminator_loss_fake', d_loss_fake)\n",
    "\n",
    "d_real_count_ph = tf.placeholder(tf.float32)\n",
    "d_fake_count_ph = tf.placeholder(tf.float32)\n",
    "g_count_ph = tf.placeholder(tf.float32)\n",
    "\n",
    "tf.summary.scalar('d_real_count', d_real_count_ph)\n",
    "tf.summary.scalar('d_fake_count', d_fake_count_ph)\n",
    "tf.summary.scalar('g_count', g_count_ph)\n",
    "\n",
    "d_on_generated = tf.reduce_mean(discriminator(generator(batch_size, z_dimensions)))\n",
    "d_on_real = tf.reduce_mean(discriminator(x_placeholder))\n",
    "\n",
    "tf.summary.scalar('d_on_generated_eval', d_on_generated)\n",
    "tf.summary.scalar('d_on_real_eval', d_on_real)\n",
    "\n",
    "images_for_tensorboard = generator(batch_size, z_dimensions)\n",
    "tf.summary.image('Generated_images', images_for_tensorboard, 10)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/gan/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "print(logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "gLoss = 0\n",
    "dLossFake, dLossReal = 1, 1\n",
    "d_real_count, d_fake_count, g_count = 0, 0, 0\n",
    "for i in range(3651):\n",
    "    if dLossFake > 0.6:\n",
    "        # Train discriminator on generated images\n",
    "        _, dLossReal, dLossFake, gLoss = sess.run([d_trainer_fake, d_loss_real, d_loss_fake, g_loss],\n",
    "                                                    {x_placeholder: X_final})\n",
    "        d_fake_count += 1\n",
    "\n",
    "    if gLoss > 0.5:\n",
    "        # Train the generator\n",
    "        _, dLossReal, dLossFake, gLoss = sess.run([g_trainer, d_loss_real, d_loss_fake, g_loss],\n",
    "                                                    {x_placeholder: X_final})\n",
    "        g_count += 1\n",
    "\n",
    "    if dLossReal > 0.45:\n",
    "        # If the discriminator classifies real images as fake,\n",
    "        # train discriminator on real values\n",
    "        _, dLossReal, dLossFake, gLoss = sess.run([d_trainer_real, d_loss_real, d_loss_fake, g_loss],\n",
    "                                                    {x_placeholder: X_final})\n",
    "        d_real_count += 1\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        summary = sess.run(merged, {x_placeholder: X_final, d_real_count_ph: d_real_count,\n",
    "                                    d_fake_count_ph: d_fake_count, g_count_ph: g_count})\n",
    "        writer.add_summary(summary, i)\n",
    "        d_real_count, d_fake_count, g_count = 0, 0, 0\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        # Periodically display a sample image in the notebook\n",
    "        # (These are also being sent to TensorBoard every 10 iterations)\n",
    "        images = sess.run(generator(3, z_dimensions))\n",
    "        d_result = sess.run(discriminator(x_placeholder), {x_placeholder: X_final})\n",
    "        print(\"TRAINING STEP\", i, \"AT\", datetime.datetime.now())\n",
    "        for j in range(3):\n",
    "            print(\"Discriminator classification\", d_result[j])\n",
    "            im = images[j, :, :, 0]\n",
    "            plt.imshow(im.reshape([28, 28]), cmap='Greys')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
