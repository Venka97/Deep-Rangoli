{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "sys.path.append(os.path.join('..','slim'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import functools\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfgan = tf.contrib.gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queues = tf.contrib.slim.queues\n",
    "layers = tf.contrib.layers\n",
    "ds = tf.contrib.distributions\n",
    "framework = tf.contrib.framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = 'datasetran/' # the dataset file or root folder path.\n",
    "MODE = 'folder'\n",
    "# Image Parameters\n",
    "N_CLASSES = 6 # CHANGE HERE, total number of classes\n",
    "IMG_HEIGHT = 64 # CHANGE HERE, the image height to be resized to\n",
    "IMG_WIDTH = 64 # CHANGE HERE, the image width to be resized to\n",
    "CHANNELS = 3 # The 3 color channels, change to 1 if grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leaky_relu = lambda net: tf.nn.leaky_relu(net, alpha=0.01)\n",
    "  \n",
    "\n",
    "def visualize_training_generator(train_step_num, start_time, data_np):\n",
    "    \"\"\"Visualize generator outputs during training.\n",
    "    \n",
    "    Args:\n",
    "        train_step_num: The training step number. A python integer.\n",
    "        start_time: Time when training started. The output of `time.time()`. A\n",
    "            python float.\n",
    "        data: Data to plot. A numpy array, most likely from an evaluated TensorFlow\n",
    "            tensor.\n",
    "    \"\"\"\n",
    "    print('Training step: %i' % train_step_num)\n",
    "    time_since_start = (time.time() - start_time) / 60.0\n",
    "    print('Time since start: %f m' % time_since_start)\n",
    "    print('Steps per min: %f' % (train_step_num / time_since_start))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.squeeze(data_np))\n",
    "    plt.show()\n",
    "\n",
    "def visualize_digits(tensor_to_visualize):\n",
    "    \"\"\"Visualize an image once. Used to visualize generator before training.\n",
    "    \n",
    "    Args:\n",
    "        tensor_to_visualize: An image tensor to visualize. A python Tensor.\n",
    "    \"\"\"\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        with queues.QueueRunners(sess):\n",
    "            images_np = sess.run(tensor_to_visualize)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.squeeze(images_np))\n",
    "\n",
    "def evaluate_tfgan_loss(gan_loss, name=None):\n",
    "    \"\"\"Evaluate GAN losses. Used to check that the graph is correct.\n",
    "    \n",
    "    Args:\n",
    "        gan_loss: A GANLoss tuple.\n",
    "        name: Optional. If present, append to debug output.\n",
    "    \"\"\"\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        with queues.QueueRunners(sess):\n",
    "            gen_loss_np = sess.run(gan_loss.generator_loss)\n",
    "            dis_loss_np = sess.run(gan_loss.discriminator_loss)\n",
    "    if name:\n",
    "        print('%s generator loss: %f' % (name, gen_loss_np))\n",
    "        print('%s discriminator loss: %f'% (name, dis_loss_np))\n",
    "    else:\n",
    "        print('Generator loss: %f' % gen_loss_np)\n",
    "        print('Discriminator loss: %f'% dis_loss_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Function to load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_images(dataset_path, mode, batch_size):\n",
    "    tf.reset_default_graph()\n",
    "    imagepaths, labels = list(), list()\n",
    "    if mode == 'file':\n",
    "        # Read dataset file\n",
    "        data = open(dataset_path, 'r').read().splitlines()\n",
    "        for d in data:\n",
    "            imagepaths.append(d.split(' ')[0])\n",
    "            labels.append(int(d.split(' ')[1]))\n",
    "    elif mode == 'folder':\n",
    "        # An ID will be affected to each sub-folders by alphabetical order\n",
    "        label = 0\n",
    "        # List the directory\n",
    "        \n",
    "        classes = sorted(os.walk(dataset_path).__next__()[1])\n",
    "        # List each sub-directory (the classes)\n",
    "        for c in classes:\n",
    "            c_dir = os.path.join(dataset_path, c)\n",
    "            try:  # Python 2\n",
    "                walk = os.walk(c_dir).next()\n",
    "            except Exception:  # Python 3\n",
    "                walk = os.walk(c_dir).__next__()\n",
    "            # Add each image to the training set\n",
    "            for sample in walk[2]:\n",
    "                # Only keeps jpeg images\n",
    "                if sample.endswith('.jpg') or sample.endswith('.jpeg'):\n",
    "                    imagepaths.append(os.path.join(c_dir, sample))\n",
    "                    labels.append(label)\n",
    "            label += 1\n",
    "    else:\n",
    "        raise Exception(\"Unknown mode.\")\n",
    "\n",
    "    # Convert to Tensor\n",
    "    imagepaths = tf.convert_to_tensor(imagepaths, dtype=tf.string)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "    # Build a TF Queue, shuffle data\n",
    "    image, label = tf.train.slice_input_producer([imagepaths, labels],\n",
    "                                                 shuffle=True)\n",
    "\n",
    "    # Read images from disk\n",
    "    image = tf.read_file(image)\n",
    "    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n",
    "\n",
    "    # Resize images to a common size\n",
    "    image = tf.image.resize_images(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "\n",
    "    # Normalize\n",
    "    image = image * 1.0/127.5 - 1.0\n",
    "\n",
    "    # Create batches\n",
    "    X, Y = tf.train.batch([image, label], batch_size=batch_size,\n",
    "                          capacity=batch_size * 8,\n",
    "                          num_threads=4)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "real_images,one_hot_labels = read_images(DATASET_PATH,MODE,BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_fn(noise, weight_decay=2.5e-5, is_training=True):\n",
    "    \"\"\"Simple generator to produce MNIST images.\n",
    "    \n",
    "    Args:\n",
    "        noise: A single Tensor representing noise.\n",
    "        weight_decay: The value of the l2 weight decay.\n",
    "        is_training: If `True`, batch norm uses batch statistics. If `False`, batch\n",
    "            norm uses the exponential moving average collected from population \n",
    "            statistics.\n",
    "    \n",
    "    Returns:\n",
    "        A generated image in the range [-1, 1].\n",
    "    \"\"\"\n",
    "    with framework.arg_scope(\n",
    "        [layers.fully_connected, layers.conv2d_transpose],\n",
    "        activation_fn=tf.nn.relu, normalizer_fn=layers.batch_norm,\n",
    "        weights_regularizer=layers.l2_regularizer(weight_decay)),\\\n",
    "    framework.arg_scope([layers.batch_norm], is_training=is_training,\n",
    "                        zero_debias_moving_mean=True):\n",
    "        net = layers.fully_connected(noise, 1024)\n",
    "        net = layers.fully_connected(net, 16 * 16 * 256)\n",
    "        net = tf.reshape(net, [-1, 16, 16, 256])\n",
    "        net = layers.conv2d_transpose(net, 64, [4, 4], stride=2)\n",
    "        net = layers.conv2d_transpose(net, 32, [4, 4], stride=2)\n",
    "        # Make sure that generator output is in the same range as `inputs`\n",
    "        # ie [-1, 1].\n",
    "        net = layers.conv2d(net, 3, 4, normalizer_fn=None, activation_fn=tf.tanh)\n",
    "\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_fn(img, unused_conditioning, weight_decay=2.5e-5,\n",
    "                     is_training=True):\n",
    "    \"\"\"Discriminator network on MNIST digits.\n",
    "    \n",
    "    Args:\n",
    "        img: Real or generated MNIST digits. Should be in the range [-1, 1].\n",
    "        unused_conditioning: The TFGAN API can help with conditional GANs, which\n",
    "            would require extra `condition` information to both the generator and the\n",
    "            discriminator. Since this example is not conditional, we do not use this\n",
    "            argument.\n",
    "        weight_decay: The L2 weight decay.\n",
    "        is_training: If `True`, batch norm uses batch statistics. If `False`, batch\n",
    "            norm uses the exponential moving average collected from population \n",
    "            statistics.\n",
    "    \n",
    "    Returns:\n",
    "        Logits for the probability that the image is real.\n",
    "    \"\"\"\n",
    "    with framework.arg_scope(\n",
    "        [layers.conv2d, layers.fully_connected],\n",
    "        activation_fn=leaky_relu, normalizer_fn=None,\n",
    "        weights_regularizer=layers.l2_regularizer(weight_decay),\n",
    "        biases_regularizer=layers.l2_regularizer(weight_decay)):\n",
    "        net = layers.conv2d(img, 64, [4, 4], stride=2)\n",
    "        net = layers.conv2d(net, 128, [4, 4], stride=2)\n",
    "        net = layers.flatten(net)\n",
    "        with framework.arg_scope([layers.batch_norm], is_training=is_training):\n",
    "            net = layers.fully_connected(net, 1024, normalizer_fn=layers.batch_norm)\n",
    "        return layers.linear(net, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "noise_dims = 64\n",
    "gan_model = tfgan.gan_model(\n",
    "    generator_fn,\n",
    "    discriminator_fn,\n",
    "    real_data=real_images,\n",
    "    generator_inputs=tf.random_normal([BATCH_SIZE, noise_dims]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_gan_loss = tfgan.gan_loss(\n",
    "    gan_model,\n",
    "    generator_loss_fn=tfgan.losses.minimax_generator_loss,\n",
    "    discriminator_loss_fn=tfgan.losses.minimax_discriminator_loss)\n",
    "\n",
    "evaluate_tfgan_loss(vanilla_gan_loss,'vanilla_gan_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
